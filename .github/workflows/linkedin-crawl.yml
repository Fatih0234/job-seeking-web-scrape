name: LinkedIn Crawl

concurrency:
  group: linkedin-crawl-${{ github.ref_name }}
  cancel-in-progress: false

on:
  schedule:
    # Every 12 hours (UTC)
    - cron: "0 */12 * * *"
  workflow_dispatch:
    inputs:
      sync_search_definitions:
        description: "Sync YAML search definitions into DB before crawling"
        required: false
        default: false
        type: boolean

jobs:
  crawl:
    runs-on: ubuntu-latest
    timeout-minutes: 90

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Install Playwright Chromium
        run: |
          python -m playwright install --with-deps chromium

      - name: Run unit tests
        run: |
          python -m unittest discover -s tests -p "test_*.py"

      - name: Configure run flags
        run: |
          if [ "${{ github.event_name }}" = "workflow_dispatch" ] && [ "${{ inputs.sync_search_definitions }}" = "true" ]; then
            echo "SYNC_SEARCH_DEFINITIONS=1" >> "$GITHUB_ENV"
          else
            echo "SYNC_SEARCH_DEFINITIONS=0" >> "$GITHUB_ENV"
          fi

      - name: Run crawl
        env:
          SUPABASE_HOST: ${{ secrets.SUPABASE_HOST }}
          SUPABASE_PORT: ${{ secrets.SUPABASE_PORT }}
          SUPABASE_DATABASE: ${{ secrets.SUPABASE_DATABASE }}
          SUPABASE_USER: ${{ secrets.SUPABASE_USER }}
          SUPABASE_PASSWORD: ${{ secrets.SUPABASE_PASSWORD }}
          SUPABASE_SSLMODE: ${{ secrets.SUPABASE_SSLMODE }}
          CRAWL_TRIGGER: ${{ github.event_name == 'schedule' && 'github_schedule' || 'github_manual' }}
          RUN_DISCOVERY: "1"
          RUN_DETAILS: "0"

          DISCOVERY_TPR_POLICY: auto_if_any_time
          DISCOVERY_TPR_RECENT_HOURS: "30"
          DISCOVERY_TPR_RECENT_CODE: r86400
          DISCOVERY_TPR_FALLBACK_CODE: r604800
        run: |
          python -m scripts.run_crawl

      - name: Report latest run
        if: always()
        env:
          SUPABASE_HOST: ${{ secrets.SUPABASE_HOST }}
          SUPABASE_PORT: ${{ secrets.SUPABASE_PORT }}
          SUPABASE_DATABASE: ${{ secrets.SUPABASE_DATABASE }}
          SUPABASE_USER: ${{ secrets.SUPABASE_USER }}
          SUPABASE_PASSWORD: ${{ secrets.SUPABASE_PASSWORD }}
          SUPABASE_SSLMODE: ${{ secrets.SUPABASE_SSLMODE }}
        run: |
          python -m scripts.report_latest_run

      - name: Upload artifacts (output/)
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: output
          path: output/**
          if-no-files-found: warn
